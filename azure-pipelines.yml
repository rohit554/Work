# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
- None


parameters:
  - name: environment
    displayName: Environment Parameter
    default: 'dev'
    type: string

variables:
  - name: rgprefix
    value: dg${{ parameters.environment }}
  - name: vmImageName
    value: ubuntu-latest
  - name: azureResourceManagerConnection
    value: 'Pay-As-You-Go(590f7ac0-b909-4092-adb4-2ad447a5bb19)'
  - name: subscriptionId
    value: '590f7ac0-b909-4092-adb4-2ad447a5bb19'
  - name: keyvaultsubscription
    value: ${{ variables.rgprefix }}SecretsAccess

  - group: gamificationPipelineVars
  - group: onboardingPipelineVars
  - group: datagamzGeneralPipelineVars

jobs:
- job: AnalyticsPlatformCICD
  pool:
    vmImage: ${{variables.vmImageName}}
  variables:
    resourceGroupName: ${{ variables.rgprefix }}analytics
    KeyVaultResourcename: ${{ variables.rgprefix }}secrets
    keyvaultsubscription: ${{ variables.rgprefix }}SecretsAccess
    lakestorageName: ${{ variables.rgprefix }}lakestorage
    sparkName: ${{ variables.rgprefix }}spark
    tenant_setup_pyfile: "dbfs:/mnt/datagamz/code/dganalytics/dganalytics/connectors/tenant_setup.py"
    systemsetup_pyPfx1: "dbfs:/mnt/datagamz/code/dganalytics/dganalytics/connectors/"
    systemsetup_pyMdl: "/"
    systemsetup_pySfx: _setup.py
    storageAccountName: ${{ variables.rgprefix }}realtimestorage

  steps:

  - task: AzurePowerShell@5
    inputs:
      azureSubscription: ${{variables.keyvaultsubscription}}
      ScriptType: 'FilePath'
      ScriptPath: '$(System.DefaultWorkingDirectory)/devops_utils/powershell/getstorageAccesskey.ps1'
      ScriptArguments: '${{variables.KeyVaultResourcename}} storageaccesskey storageaccesskey databricksinstanceurl databricksuri databricksaccesstoken databrickssecret'
      azurePowerShellVersion: 'LatestVersion'
    name: gettingKeyVaultVars
    displayName: Get KeyVault


  - task: AzurePowerShell@5
    inputs:
      azureSubscription: ${{variables.keyvaultsubscription}}
      ScriptType: 'FilePath'
      ScriptPath: '$(System.DefaultWorkingDirectory)/devops_utils/powershell/azcopyfoldertoblob.ps1'
      ScriptArguments: '$(System.DefaultWorkingDirectory) ${{variables.lakestorageName}} datagamz  code/temp $(storageaccesskey) '
      azurePowerShellVersion: 'LatestVersion'
    name: uploadblobfiles
    displayName: Upload Files to Blob

  - script: |
      cd $(System.DefaultWorkingDirectory)/devops_utils/python
      python3 restart_Databricks_cluster.py $(databricksuri) $(databrickssecret) ${{variables.sparkName}}"
    displayName: 'Create Tenant Environment'